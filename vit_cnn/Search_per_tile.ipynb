{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb9bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "#If using script on terminal\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a5156b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 0\n",
    "script = False\n",
    "filename = 'DES2359-6331.fits'\n",
    "#filename = input('Tile filename: ')\n",
    "if(not(script)): \n",
    "    path = '/Users/jimenagonzalez/research/DSPL/Searching-double-lenses/vit_cnn/Y6_catalog_files/'\n",
    "else:\n",
    "    path = '/data/des81.b/data/stronglens/Y6_CUTOUT_IMAGES/'\n",
    "\n",
    "\n",
    "file_path = path + filename\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "path = 'jx_vit_base_p16_224-80ecf9dd.pth'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40025396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of Images, Data and Labels\"\"\"\n",
    "\n",
    "    def __init__(self, images, data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Create a PyTorch dataset from an array of images\n",
    "\t\tand an array of labels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #return python image given the index\n",
    "        image = self.images[idx]\n",
    "        new_image = np.empty((3, 45, 45))\n",
    "        new_image[0], new_image[1], new_image[2] =  self.normalize_image(image)\n",
    "        new_image = new_image.transpose(1,2,0)\n",
    "        new_image = Image.fromarray(np.uint8(255*new_image)).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        data_point = self.data.iloc[idx].to_dict()\n",
    "        sample = {'image': self.transform(new_image), 'label': label, 'img': image, 'data': data_point}\n",
    "        return sample\n",
    "    \n",
    "    def normalize_image(self, image):\n",
    "        image_g = (image[0]-np.mean(image[0]))/ np.std(image[0])\n",
    "        image_r = (image[1]-np.mean(image[1]))/ np.std(image[1])\n",
    "        image_i = (image[2]-np.mean(image[2]))/ np.std(image[2])\n",
    "\n",
    "        image_g = (image_g-np.min(image_g))/ (np.max(image_g) - np.min(image_g))\n",
    "        image_r = (image_r-np.min(image_r))/ (np.max(image_r) - np.min(image_r))\n",
    "        image_i = (image_i-np.min(image_i))/ (np.max(image_i) - np.min(image_i))\n",
    "        return(image_i, image_r, image_g)\n",
    "    \n",
    "    def plot_image(self, idx):\n",
    "        image = images[idx]\n",
    "        new_image = np.empty((3, 45, 45))\n",
    "        new_image[0], new_image[1], new_image[2] =  self.normalize_image(image)\n",
    "        new_image = new_image.transpose(1,2,0)\n",
    "        new_image = Image.fromarray(np.uint8(255*new_image)).convert(\"RGB\")\n",
    "        #new_image = Image.fromarray(np.uint16(255*new_image)).convert(\"RGB\")\n",
    "        \n",
    "        plt.figure(figsize=(12,4)) \n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.asarray(new_image))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        rgb = make_lupton_rgb(image[2], image[1], image[0], Q=11., stretch=40.)\n",
    "        plt.imshow(rgb, aspect='equal')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfb280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_datasets(images, data, labels, test_size=0.2, transform=None):\n",
    "    \"\"\"\n",
    "\tMake training and testing datasets\n",
    "\t\n",
    "\tArgs:\n",
    "\t    images: 3D array of all images\n",
    "        labels: 1D array of the labels for each image\n",
    "        test_size: the fraction of the images to use as the test dataset\n",
    "\t\ttransform: the PyTorch transformation to apply to the data\n",
    "\t\t\n",
    "\tReturns\n",
    "\t    train_dataset: An instance of the ImageDataset Class for training\n",
    "\t\ttest_dataset: An instance of the ImageDataset Class for testing\n",
    "\t\"\"\"\n",
    "\n",
    "    # Shuffle and split data\n",
    "    y = labels\n",
    "    train_images, test_images, train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        images, data, labels, test_size=test_size, random_state=6, stratify=y)\n",
    "    \n",
    "    # Create a PyTorch Dataset\n",
    "    return (ImageDataset(train_images, train_data, train_labels, transform=transform),\n",
    "            ImageDataset(test_images, test_data, test_labels, transform=transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aefbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTBase16(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, pretrained=False):\n",
    "        \n",
    "        super(ViTBase16, self).__init__()\n",
    "        \n",
    "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        if (pretrained):\n",
    "            path = 'jx_vit_base_p16_224-80ecf9dd.pth'\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3f7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTBase16(n_classes=2, pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "name = 'model.pt'#'model.pt'#'other.pt' \n",
    "model = torch.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed029c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tile(file_path, prob_lim):\n",
    "    hdu_list = fits.open(file_path)\n",
    "    search_ids = pd.DataFrame(hdu_list[1].data)\n",
    "    search_labels = 2*np.ones(len(search_ids), dtype = np.int64)\n",
    "   \n",
    "    int_arr = hdu_list[2].data    # change 2->3 for PSFs \n",
    "    img_min = hdu_list[4].data    # change 4->6 for PSFs\n",
    "    img_scale = hdu_list[5].data  # change 5->7 for PSFs\n",
    "    search_images = int_arr / 65535 * img_scale[:,:,np.newaxis,np.newaxis] + img_min[:,:,np.newaxis,np.newaxis]\n",
    "\n",
    "    search_dataset = ImageDataset(search_images, search_ids, search_labels, transform=transform)\n",
    "    search_loader = torch.utils.data.DataLoader(dataset=search_dataset, batch_size=1, num_workers=num_workers, shuffle=True)\n",
    "    \n",
    "    positives = np.zeros((1,4,45,45))\n",
    "    data_results = np.zeros((1, 2))\n",
    "    columns = ['COADD_OBJECT_ID']\n",
    "    positive_ids = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for i_batch, sample in enumerate(tqdm(search_loader)):\n",
    "        #if(i_batch==6000): break\n",
    "        sample_image, sample_label, sample_img, sample_data = sample['image'], sample['label'] , sample['img'], sample['data']\n",
    "        \n",
    "        output = model(sample_image)\n",
    "        predicted = output.argmax(dim=1).item()\n",
    "    \n",
    "        prob = nn.Softmax(dim=1)(output)\n",
    "        prob = prob[:,0].detach().numpy()[0]\n",
    "    \n",
    "        predicted = 0 if prob >= prob_lim else 1\n",
    "    \n",
    "        if(predicted == 1):\n",
    "            positives = np.append(positives, [np.array(sample_img[0])], axis = 0)\n",
    "            new_df = pd.DataFrame.from_dict(sample_data)\n",
    "            new_df['Prob'] = prob\n",
    "            positive_ids = positive_ids.append(new_df, ignore_index=True)\n",
    "    \n",
    "    positives = np.delete(positives, 0, axis = 0)\n",
    "    \n",
    "    if(len(positive_ids) > 0):\n",
    "        print('Found {} single lenses in this tile.'.format(len(positive_ids)))\n",
    "        primary = fits.PrimaryHDU()\n",
    "        image = fits.ImageHDU(positives, name=\"IMAGE\")\n",
    "        data_results = Table.from_pandas(new_df)\n",
    "        hdu_list = fits.HDUList([primary, image])\n",
    "        hdu_list.writeto('Y6_detections/' + filename[:-5] + '.fits', overwrite=True)\n",
    "        positive_ids.to_csv('Y6_detections/' + filename[:-5] + '_ids.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d5e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DES2359-6331.fits\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af580e4b1174b24b5b37ac87dbc88fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15192 single lenses in this tile.\n",
      "Maximum memory usage: 3480.91796875\n"
     ]
    }
   ],
   "source": [
    "prob_lim = 0.3\n",
    "print(filename)\n",
    "mem_usage = memory_usage(( search_tile, (file_path, prob_lim )))\n",
    "print('Maximum memory usage: %s' % max(mem_usage))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
