{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f101eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "#If using script on terminal\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b466c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset of Images, Data and Labels\"\"\"\n",
    "\n",
    "    def __init__(self, images, data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Create a PyTorch dataset from an array of images\n",
    "\t\tand an array of labels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #return python image given the index\n",
    "        image = self.images[idx]\n",
    "        new_image = np.empty((3, 45, 45))\n",
    "        new_image[0], new_image[1], new_image[2] =  self.normalize_image(image)\n",
    "        new_image = new_image.transpose(1,2,0)\n",
    "        new_image = Image.fromarray(np.uint8(255*new_image)).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        data_point = self.data.iloc[idx].to_dict()\n",
    "        sample = {'image': self.transform(new_image), 'label': label, 'img': image, 'data': data_point}\n",
    "        return sample\n",
    "    \n",
    "    def normalize_image(self, image):\n",
    "        image_g = (image[0]-np.mean(image[0]))/ np.std(image[0])\n",
    "        image_r = (image[1]-np.mean(image[1]))/ np.std(image[1])\n",
    "        image_i = (image[2]-np.mean(image[2]))/ np.std(image[2])\n",
    "\n",
    "        image_g = (image_g-np.min(image_g))/ (np.max(image_g) - np.min(image_g))\n",
    "        image_r = (image_r-np.min(image_r))/ (np.max(image_r) - np.min(image_r))\n",
    "        image_i = (image_i-np.min(image_i))/ (np.max(image_i) - np.min(image_i))\n",
    "        return(image_i, image_r, image_g)\n",
    "    \n",
    "    def plot_image(self, idx):\n",
    "        image = images[idx]\n",
    "        new_image = np.empty((3, 45, 45))\n",
    "        new_image[0], new_image[1], new_image[2] =  self.normalize_image(image)\n",
    "        new_image = new_image.transpose(1,2,0)\n",
    "        new_image = Image.fromarray(np.uint8(255*new_image)).convert(\"RGB\")\n",
    "        #new_image = Image.fromarray(np.uint16(255*new_image)).convert(\"RGB\")\n",
    "        \n",
    "        plt.figure(figsize=(12,4)) \n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.asarray(new_image))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        rgb = make_lupton_rgb(image[2], image[1], image[0], Q=11., stretch=40.)\n",
    "        plt.imshow(rgb, aspect='equal')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51e3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_datasets(images, data, labels, test_size=0.2, transform=None):\n",
    "    \"\"\"\n",
    "\tMake training and testing datasets\n",
    "\t\n",
    "\tArgs:\n",
    "\t    images: 3D array of all images\n",
    "        labels: 1D array of the labels for each image\n",
    "        test_size: the fraction of the images to use as the test dataset\n",
    "\t\ttransform: the PyTorch transformation to apply to the data\n",
    "\t\t\n",
    "\tReturns\n",
    "\t    train_dataset: An instance of the ImageDataset Class for training\n",
    "\t\ttest_dataset: An instance of the ImageDataset Class for testing\n",
    "\t\"\"\"\n",
    "\n",
    "    # Shuffle and split data\n",
    "    y = labels\n",
    "    train_images, test_images, train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        images, data, labels, test_size=test_size, random_state=6, stratify=y)\n",
    "    \n",
    "    # Create a PyTorch Dataset\n",
    "    return (ImageDataset(train_images, train_data, train_labels, transform=transform),\n",
    "            ImageDataset(test_images, test_data, test_labels, transform=transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd70741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 0\n",
    "script = False\n",
    "filename = 'DES2359-6331.fits'\n",
    "if(not(script)): \n",
    "    path = '/Users/jimenagonzalez/research/DSPL/Searching-double-lenses/vit_cnn/Y6_catalog_files/'\n",
    "else:\n",
    "    path = '/data/des81.b/data/stronglens/Y6_CUTOUT_IMAGES/'\n",
    "\n",
    "\n",
    "file_path = path + filename\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "path = 'jx_vit_base_p16_224-80ecf9dd.pth'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00df09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTBase16(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, pretrained=False):\n",
    "        \n",
    "        super(ViTBase16, self).__init__()\n",
    "        \n",
    "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        if (pretrained):\n",
    "            path = 'jx_vit_base_p16_224-80ecf9dd.pth'\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844ea669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTBase16(n_classes=2, pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "name = 'model.pt'#'model.pt'#'other.pt' \n",
    "model = torch.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06f8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tile(file_path, prob_lim):\n",
    "    hdu_list = fits.open(file_path)\n",
    "    search_ids = pd.DataFrame(hdu_list[1].data)\n",
    "    search_images = hdu_list[2].data\n",
    "    search_images.dtype = np.float16\n",
    "    search_labels = 2*np.ones(len(search_ids), dtype = np.int64)\n",
    "\n",
    "    search_dataset = ImageDataset(search_images, search_ids, search_labels, transform=transform)\n",
    "    search_loader = torch.utils.data.DataLoader(dataset=search_dataset, batch_size=1, num_workers=num_workers, shuffle=True)\n",
    "    \n",
    "    positives = np.zeros((1,4,45,45))\n",
    "    columns = ['COADD_OBJECT_ID']\n",
    "    positive_ids = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for i_batch, sample in enumerate(tqdm(search_loader)):\n",
    "        #if(i_batch==2): break\n",
    "        sample_image, sample_label, sample_img, sample_data = sample['image'], sample['label'] , sample['img'], sample['data']\n",
    "        \n",
    "        output = model(sample_image)\n",
    "        predicted = output.argmax(dim=1).item()\n",
    "    \n",
    "        prob = nn.Softmax(dim=1)(output)\n",
    "        prob = prob[:,0].detach().numpy()[0]\n",
    "    \n",
    "        predicted = 0 if prob >= prob_lim else 1\n",
    "    \n",
    "        if(predicted == 0):\n",
    "            print('Positive!')\n",
    "            positives = np.append(positives, [np.array(sample_img[0])], axis = 0)\n",
    "            positive_ids = positive_ids.append(pd.DataFrame.from_dict(sample_data), ignore_index=True)\n",
    "    \n",
    "    positives = np.delete(positives, 0, axis = 0)\n",
    "    \n",
    "    if(len(positive_ids) > 0):\n",
    "        positive_ids.to_csv(filename[:-5] + '_pos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7a117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51821fd173942a5a87af09e9c3077cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:179: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in subtract\n",
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:212: RuntimeWarning: invalid value encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n",
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py:230: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in subtract\n",
      "/Users/jimenagonzalez/Software/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "prob_lim = 0.95\n",
    "mem_usage = memory_usage(( search_tile, (file_path, prob_lim )))\n",
    "print('Maximum memory usage: %s' % max(mem_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
